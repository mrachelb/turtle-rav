{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T09:55:58.172288Z",
     "start_time": "2024-05-22T09:55:58.166267Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, PoissonRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading all files into Panda frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T09:55:58.180520Z",
     "start_time": "2024-05-22T09:55:58.173001Z"
    }
   },
   "outputs": [],
   "source": [
    "capture_site = pd.read_csv('data/CaptureSite_category.csv')\n",
    "sample_sub = pd.read_csv('data/Sample_sub.csv')\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop irrelvant columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T09:55:58.285965Z",
     "start_time": "2024-05-22T09:55:58.282815Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Standartising column names \n",
    "def standardize_column_names(col):\n",
    "    # Replace spaces with underscores\n",
    "    col = col.replace(' ', '_')\n",
    "    # Insert underscore before each uppercase letter preceded by a lowercase letter or followed by a lowercase letter\n",
    "    col = re.sub(r'(?<=[a-z])(?=[A-Z])', '_', col)\n",
    "    col = re.sub(r'(?<=[A-Z])(?=[A-Z][a-z])', '_', col)\n",
    "    # Convert to lower case\n",
    "    col = col.lower()\n",
    "    # Ensure single underscores only (in case of consecutive underscores from initial spaces)\n",
    "    col = re.sub(r'_+', '_', col)\n",
    "    return col\n",
    "\n",
    "train_df.columns = [standardize_column_names(col) for col in train_df.columns]\n",
    "\n",
    "# Printing the updated column names to verify the changes\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['rescue_id', 'turtle_characteristics', 'tag_1', 'tag_2', 'lost_tags', 't_number', 'sex', 'capture_method', 'release_site', 'landing_site', 'status', 'foraging_ground']\n",
    "\n",
    "train_df = train_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Helpmethods and clean the columns 'fischer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T09:55:58.298738Z",
     "start_time": "2024-05-22T09:55:58.296236Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract a number of String of the form XXXX_000\n",
    "\n",
    "def extract_number_split(s):\n",
    "    num = s.split('_')[-1]\n",
    "    return int(num)\n",
    "\n",
    "extract_number_split('Fischer_5')\n",
    "\n",
    "\n",
    "train_df['fisher'] = train_df['fisher'].apply(extract_number_split)\n",
    "train_df['researcher'] = train_df['researcher'].apply(extract_number_split)\n",
    "train_df['capture_site'] = train_df['capture_site'].apply(extract_number_split)\n",
    "train_df['species'] = train_df['species'].apply(extract_number_split)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert and split datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T09:55:58.426562Z",
     "start_time": "2024-05-22T09:55:58.349726Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_and_split_datetime(df, columns):\n",
    "    \"\"\"\n",
    "    Convert specified datetime columns to timestamp and split into year and week columns\n",
    "    with new names based on the original column names.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the columns.\n",
    "    columns (list): List of column names to convert and split.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with new year and week columns.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        # Convert the column to datetime\n",
    "        df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "\n",
    "        # Extract the base name without 'date_time_' prefix\n",
    "        base_name = column.replace('date_time_', '')\n",
    "\n",
    "        # Create new columns for year and week with the desired names\n",
    "        df[f'year_{base_name}'] = df[column].dt.year\n",
    "        df[f'week_{base_name}'] = df[column].dt.isocalendar().week\n",
    "\n",
    "        # Drop the original datetime column if desired\n",
    "        df.drop(columns=[column], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# Assuming 'df' is your DataFrame\n",
    "columns_to_convert = ['date_time_caught', 'date_time_release']\n",
    "train_df = convert_and_split_datetime(train_df, columns_to_convert)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Knn on ccl_cm and ccw_cm to compute the 5409 missing values of weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "def imput_missing_weight_values(df, n = 5):\n",
    "    knn_df = df[['ccl_cm', 'ccw_cm', 'weight_kg']]\n",
    "    imputer = KNNImputer(n_neighbors=n)\n",
    "    imputer.set_output(transform='pandas')\n",
    "\n",
    "    return imputer.fit_transform(knn_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column(df):\n",
    "    # Split the column into three parts\n",
    "    split_columns = df['SiteInfo'].str.split('_', expand=True)\n",
    "\n",
    "# Assign these parts to new columns in the DataFrame\n",
    "    df['site'] = split_columns[0]\n",
    "    df['y'] = split_columns[1]\n",
    "    df['Year'] = split_columns[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = imput_missing_weight_values(train_df)\n",
    "train_df['ccl_cm'] = imputed_df['ccl_cm']\n",
    "train_df['ccw_cm'] = imputed_df['ccw_cm']\n",
    "train_df['weight_kg'] = imputed_df['weight_kg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=[  'year_release',\n",
    "       'week_release'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('Data/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['year_week'] = (100 *train_df.year_caught) + train_df.week_caught\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['year_week'] = train_df['year_week'].astype(str)\n",
    "train_df['capture_site'] = train_df['capture_site'].astype(str)\n",
    "\n",
    "train_df['ID'] = 'CaptureSite_'+ train_df['capture_site']+ '_' + train_df['year_week']\n",
    "train_df.drop(columns=['capture_site','week_caught','year_week' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median  = train_df.groupby('ID').median().reset_index()\n",
    "\n",
    "df_mean  = train_df.groupby('ID').mean().reset_index()\n",
    "df_size = train_df.groupby('ID').size().reset_index(name='Capture_Number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Capture_Number'] = df_size['Capture_Number']\n",
    "\n",
    "df['ccl_cm'] =  df_mean['ccl_cm'] \n",
    "df['ccw_cm'] =  df_mean['ccw_cm'] \n",
    "df['weight_kg'] =  df_mean['weight_kg'] \n",
    "\n",
    "df['researcher'] =  df_median['researcher'] \n",
    "df['fisher'] =  df_median['fisher'] \n",
    "df['species'] =  df_median['species'] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('data/Sample_sub.csv')\n",
    "sample_sub.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_colum(df_split):\n",
    "    split_columns = df_split['ID'].str.split('_', expand=True)\n",
    "    year_week = split_columns[2]\n",
    "    year_week= year_week.astype(str)\n",
    "    year = year_week.str.slice(2, 4)\n",
    "    week = year_week.str.slice(5, 6)\n",
    "\n",
    "\n",
    "\n",
    "    df_split['year'] = year.astype(int)\n",
    "    df_split['week'] = week.astype(int)\n",
    "\n",
    "    df_split['site'] = split_columns[1].astype(int)\n",
    "    df_split.drop(columns = 'ID')\n",
    "    return df_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_colum(sample_sub)\n",
    "sample_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = split_colum(df_size)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['year', 'week', 'site']]\n",
    "y = df['Capture_Number']\n",
    "\n",
    "X_test = sample_sub[['year', 'week', 'site']]\n",
    "y_test = sample_sub['Capture_Number']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_error_score(y_test, y_pred):\n",
    "    print('mean_squared_error: ' , mean_squared_error(y_test, y_pred))\n",
    "    print('root mean_squared_error: ' , np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print('mean_absolute_error: ' , mean_absolute_error(y_test, y_pred))\n",
    "    print('r2_score: ' , r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LinearRegression()\n",
    "lg.fit(X,y)\n",
    "y_pred = lg.predict(X_test)\n",
    "print('---- Lienar--------')\n",
    "print_error_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForesst = RandomForestRegressor(random_state= 100, )\n",
    "#randomForesst.fit(X, y)\n",
    "#y_pred_randomForest = randomForesst.predict(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': range(0, 1000, 100),\n",
    "    'criterion': [ 'squared_error', 'absolute_error']\n",
    "}\n",
    "grid_search_random = GridSearchCV(estimator=randomForesst, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search_random.fit(X=X, y=y)\n",
    "\n",
    "y_pred_randomForest = grid_search_random.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('---- Random Forest ------')\n",
    "print_error_score(y_test, y_pred_randomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ridge Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "#ridge.fit(X, y)\n",
    "#y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': range(0, 1000, 1),\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "grid_search_ridge = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search_ridge.fit(X=X, y=y)\n",
    "\n",
    "y_pred_ridge = grid_search_ridge.predict(X_test)\n",
    "\n",
    "\n",
    "print(grid_search_ridge.best_estimator_)\n",
    "\n",
    "print('------Ridge----------')\n",
    "print_error_score(y_test, y_pred_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PoissonRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson = PoissonRegressor()\n",
    "#ridge.fit(X, y)\n",
    "#y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': range(0, 100, 1),\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "grid_search_ridge = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search_ridge.fit(X=X, y=y)\n",
    "\n",
    "y_pred_ridge = grid_search_ridge.predict(X_test)\n",
    "\n",
    "\n",
    "print(grid_search_ridge.best_estimator_)\n",
    "\n",
    "print('------Ridge----------')\n",
    "print_error_score(y_test, y_pred_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X , y):\n",
    "    # Splitting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(  \n",
    "    X, Y, test_size = 0.3, random_state = 100) \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
